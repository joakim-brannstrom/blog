# Parallelize Datacat part 2

In the previous [article]() I talked about the initial work of parallelizing Datacat. I would dare say that the improvements in the end where acceptably good. But at the end I did mention an observation that I saw when analyzing the behavior of `datacat` for the larger datasets. Namely that it *seems* to be stuck in a single thread at the end for a noticeable time. My suspicion is that this is the call to `Variable.complete`. Let us investigate this and see if we can parallelize it.

**Note**: The parallelizing has focused on smaller blocks. In the future I may do a rewrite to a more *dataflow* centric architecture. I'll also explore if [DCompute]() can be used. I do see a similarity between image processing with *kernels* and what a *rule* in `datacat` do with data consisting of simple types.

# Analyze

Let us start by gather data before jumping to any conclusions. A hunch is a good start but let us support it with data. I think the following will be enough:
 * [DMD]() instrumentation
 * manual instrumentation of the source code to see how much time is spent in `Variable.complete`.

Just for kicks and fun let us also run with [valgrin allocator checker](). It is so easy so why not?

## Profile

Lets gather some new profile data once again but this time from a the `http_df` dataset.

To reproduce the results I give you:
```sh
cd test/standalone
dub build -p profile
./build/graspan1 http_df

profdump -d -f trace.log trace.dot
dot -Tsvg trace.dot -o trace.svg
```



# Parallelize Datacat

[datacat](https://github.com/joakim-brannstrom/datacat) is a port of [datafrog](https://github.com/rust-lang-nursery/datafrog) to D. After I achieved my goal of being at least equivalent in performance to the Rust implementation I turned my eye to parallelism. Could I improve performance even further by leveraging parallelism?

# Analyze

Before doing any optimization it is important to understand what part of your program that is the bottlenecks. To find this out for `datacat` I implemented some benchmarks for the high level API functions `join`, `antiJoin` and `map`. See implementation of [join+antiJoin](https://github.com/joakim-brannstrom/datacat/blob/master/source/datacat/join.d) and [map](https://github.com/joakim-brannstrom/datacat/blob/master/source/datacat/map.d).

This is implemented as a separate program that uses `datacat` as a library to make it possible to profile various aspects. The benchmark program writes the final results to a CSV file.

**Note**: The benchmark test suite were initially written as a unit test suite but this didn't work as expected when I wanted to compile with all optimizations turned on.

The CSV file contains coarse grained performance data. It is kind a boring to stare at numbers thus I wanted to visualize the data in some way. Visualization also helps when comparing a larger data set.

It wasn't obvious for me how to best visualize the data in the CSV file. I first tried to create pretty graphs with [gnuplot](http://www.gnuplot.info/). But I gave up in frustration. I never managed to achieve the results I wanted.

Then a bug tickled my mind. A friend had told me that R is good for plotting. But learning R for a little, simple plot? Creating a dependency on a whole new toolchain? Luckily for me there is a port of [ggplot2](https://www.statmethods.net/advgraphs/ggplot2.html) to D, [ggplotd](https://github.com/BlackEdder/ggplotd).

It [worked like a charm](https://github.com/joakim-brannstrom/datacat/blob/master/test/make_graph_from_benchmark.d)!

Here is an example of a plot:
![plot of coarse grained data](https://github.com/joakim-brannstrom/blog/blob/master/assets/2018-07-24/profile_graph.png)

For anyone wanting to create plots I highly recommend the approach that `ggplot` have to creating graphs. In my opinion it is a lot easier than [matplotlib](https://matplotlib.org/) for Python.

## Profiling

Now with that out of the way I wanted to have detailed performance data from what parts of the program that are my bottlenecks. I thus turned to profiling.

This is easy to achieve with the [DMD](https://dlang.org/download.html#dmd) compiler. It isn't the *best* tool for profiling but it is easy to use.

There do exist a build profile but it doesn't compile in `releaseMode`. I want the profiling to be as close to the real thing as possible. To be able to control this I chose to instead add a new [build options](https://code.dlang.org/package-format?lang=sdl) to my `dub.sdl`.
```diff
buildType "utProf" {
    buildOptions "debugInfo" "profile" "optimize" "inline" "releaseMode"
}
```

And recompiled the benchmarks with this profile and executed it:
```sh
cd test
dub build -b utProf
./build/datacat_benchmark
```

This resulted in a `trace.log` and `trace.def` file. I have no idea what the `trace.def` file is. The `trace.log` is the one I want. But is it hard to read that file!

### Reading DMD Profile Log

The explanations here are what I managed to gather from the [D forum](https://forum.dlang.org/). The words are not my own. Credit goes to those that wrote it.

Top part of a `trace.log`:
```sh
------------------
    1    A
 1095    B
 1856    C
D      2952    122732995    3009972
```

D is called 2952 times. 1 of those calls comes from A. 1095 come from B.  1856 come from C. Note that 1+1095+1856 = 2952. (The A, B, C counts are called the "fan in".) The "fan out" is a list of counts of what D calls, and follows the line for D.

The total number of timer ticks spent in D is 3009972, excluding whatever D calls. The total number of timer ticks in D, including whatever D calls, is 122732995.

From this information you can not only determine where the time is being consumed, but *why*, as you know where the calls are coming from.  You can do this to determine the runtime relationships between functions, which can be used to set the link order (and this is output by the profiler in the form of a .def file).

Bottom part of a `trace.log`:
```d
======== Timer Is 3579545 Ticks/Sec, Times are in Microsecs ========

  Num          Tree        Func        Per
  Calls        Time        Time        Call

1000000   390439368   265416744         265     pure nothrow @safe char[] std.array.array!(std.conv.toChars!(10, char, 1, int).toChars(int).Result).array(std.conv.toChars!(10, char, 1, int).toChars(int).Result)
1000000    83224994    83224994          83     pure nothrow ref @nogc @safe std.conv.toChars!(10, char, 1, int).toChars(int).Result std.conv.toChars!(10, char, 1, int).toChars(int).Result.__ctor(int)
23666670 1182768507    73190160           3     _Dmain
1000000   525732328    35191373          35     pure nothrow @trusted immutable(char)[] std.conv.toImpl!(immutable(char)[], int).toImpl(int, uint, std.ascii.LetterCase)
```

 - `Num Calls` is the number of calls made to that function
 - `Tree Time` is the total cumulative time spent in the function and its subfunctions
 - `Func Time` is the total time spent in the function only
 - `Per Call` is the average time spent in the function only

The functions are sorted by their `Func Time`. As we can see what took the most time was converting the range of chars to an array in order to store it in a string.

### Datacat `trace.log`

Luckily me (second time) there is an excellent analyzer [profdump](https://code.dlang.org/packages/profdump) that can transform a profile log to e.g. a dot graph. Unfortunately I ran into a bug. Somehow druntime is unable to deduce the timer frequency of my computer (too old?) and thus printed this line in the log.
`======== Timer frequency unknown, Times are in Megaticks ========`

`profdump` did not like that one. But no despair. We are programmers? We solve problems for a living? Yes we do. After a quick look at the stack trace I managed to locate the problem and solve it.

**Note**: The bug is fixed in v0.4.3.

Here are the commands I used in the end.
```sh
profdump -d -f -t 1.0 trace.log trace.dot
dot -Tsvg trace.dot -o trace.svg
```

I had to add a threshold (-t) because the figure became too large to read otherwise.

The end results is this pretty figure:
![performance bottlenecks](https://github.com/joakim-brannstrom/blog/blob/master/assets/2018-07-24/profile_before_singlethread_optimization.svg)

## Summary

All this job to get here. Why? Listen to your elders. Everyone that I have heard of that is knowledgeable says to measure first then optimize.

It is two fold.
 * You need a way to **validate** that the changes actually improve the performance. This is why I have the coarse grained data and tools to compare the gathered data.
 * You **must** understand what the bottlenecks are **before** doing any optimizations. This is why I have the profile data and visualization.

It honestly took me a couple of days to do the preparations. This is the nice thing though with doing it at your spare time. You can do it at your pace. No stress, no worries but still a clear goal to work towards. My brain works better under these conditions compared to a stressful deadline. Yours?

# Optimization of `join`

The graph clearly show that `join` is the culprit. Further down in the call stack it shows that the time is spent at sorting ranges.

I do not think that the sorting can be avoided. But can it be done in parallel? For primitive types this shouldn't be a problem.

A design to keep in mind is that multithreading should be *optional*. Only parallelize if the user wants that behavior.

## Iteration

A user normally create variables via the `Iteration` type. My approach is to make `Iteration` into a template that take a parameter at compile time. This changes the behavior from single to multithreaded. This in turn affects all variables that are created via the `Iteration` type.

I hope that this will make it somewhat ergonomic for the user.

Lets see how it would be if we parallelize `changed`. From the call graph I do not expect this to have a major effect.
(Coding away)

After I finished the implementation of a parallel `changed` and fine tuned the API for creating parallel `Iteration` I came back to the benchmark test suite.
I implemented a new test, `perf_parallel_join`, where I create 10 variables that is continuously updated.

The results where very disappointing (and expected):
```sh
Running perf_parallel_join
single   (4 secs, 262 ms, 494 μs, and 1 hnsec)
parallel (4 secs, 274 ms, 481 μs, and 4 hnsecs)
```

No change!
This is why it is so important to have a test suite to **validate** the code changes. This means that the changes are ineffective. They only complicate the implementation. I reverted back `changed` to the single threaded, simple implementation.

But the good thing is that we now have the infrastructure to create parallel `Relation`s! Lets do that. Lets implement that parallel sort. That surely should result in some markedly improvements.

Where do I add the parallel sort? In each datalog function such as `join`, `antiJoin` and `map`? No that spreads out. The crucial part is the sort in Relation. I want to minimize the places I have to modify to make use of a parallel sort. I also want to *somehow* make it easy to do the correct thing when somebody uses the library.

This do require some changes to `Relation`. It has to be *aware* of the *sorted property* of the input. I looked into how [phobos](https://dlang.org/phobos/index.html) do this for the different sort functions defined in [std.algorithm.sorting](https://dlang.org/phobos/std_algorithm_sorting.html). If the input range can be implicitly converted to a `SortedRange`, defined in [std.range](https://dlang.org/phobos/std_range.html#SortedRange), it means that the input do not need to be sorted. Use as is. This is exactly what I want `Relation` to do in its constructor.

Where do I add `ThreadStrategy` to `Relation`?

I do not think it is a good idea to make a new type that is dependent on the `ThreadStrategy`. To avoid this I extended the constructor of `Relation`. This may be the wrong decision because that mean that `Relation.merge` is always single threaded. Lets see later on what the profiling data tells us.

This is what the constructor looks like after the modifications.
```d
this(ThreadStrategy TS = ThreadStrategy.single, T, ARGS...)(T other, auto ref ARGS args)
        if (isInputRange!T && is(ElementType!T == TupleT)
            && (TS == ThreadStrategy.parallel && ARGS.length == 1
            && is(ARGS[0] == TaskPool) || TS == ThreadStrategy.single)) {
```
It uses variable number of arguments to make it possible to have one constructor for both single and parallel sort. It also makes it possible to check at compile time that a `TaskPool` instance is provided and only for when it is relevant (parallel).

The implementation of the parallel sort is taken from the standard library, [std.parallelism](https://dlang.org/phobos/std_parallelism.html#.task). It is well tested (I assume) so lets start by using it as is.

So far we have now made `Iteration`, `Variable` and `Relation` aware of `ThreadStrategy`. The last piece of the puzzle is to make `datacat.join.join` create a `Relation` that uses the chosen `ThreadStrategy` during construction. This where achieved by adding a new template parameter, `ThreadStrategy TS`, that propagates `TS` to the constructor of `Relation`. The `TaskPool` is taken from the output parameter via introspection.

This is the six lines of magic:
```d
Relation!(Input1T.TT) rel;
static if (hasMember!(OutputT, "taskPool"))
    rel.__ctor!(TS)(results.data, output.taskPool);
else
    static assert(0, "output (" ~ OutputT.stringof ~ ") has no member taskPool");
output.insert(rel);
```

What is the end result when running the coarse grained benchmarks?
```sh
single   (414 ms, 95 μs, and 1 hnsec)
parallel (353 ms, 364 μs, and 8 hnsecs)
```

Nice! That is a 15% improvement on a small dataset.

# Parallelize Graspan1

We are not done yet. As a last precaution that the optimization really helped lets parallelize the `graspan1` application. This makes it possible for us to run it on *huge* datasets.

The needed changes where pretty minimal because by changing the strategy for `Iteration` it then propagates throughout the instances. I changed the `bench` function to be a template that takes an `Iteration` by reference.
```d
void run(T)(ref T iter) { ... }
auto iter = makeIteration!(ThreadStrategy.parallel);
run(iter);
```

Lets see what the results are when running on some of the datasets from [here](https://drive.google.com/drive/folders/0B8bQanV_QfNkbDJsOWc2WWk4SkE).

| Dataset            | Single | Multi | Improvement |
|--------------------|--------|-------|-------------|
| http_def 169M      | 3.44s  | 2.84s | 17%         |
| lnx_kernel_df 818M | 20.1s  | 17.3s | 13%         |
| pgs_df 639M        | 10.1s  | 9.20s |  9%         |

Not bad, not bad at all. A nice improvement. It maps well to the coarse grained test that showed a 15% improvement. But it also shows that sort may not be the most problematic bottleneck when the dataset grows. From a casual observation of the thread activity they seem to hover around ~20% utilization. The last seconds before it finished it seem to *hang* in one thread. This is most probably the call to `complete`.

This my folk is why it is so important to have a test suite.

Yes, multithreading helped in this case. Not by a lot but an improvement is an improvement. The answer to the question at the beginning is thus **yes**.

This is the end of this blog post. In the future I'll look into other ways of improving the performance.

# Credit

Patrik Bergström for proof reading and feedback.

# Observations of the Garbage Collector

I haven't found the garbage collector in D to be of a performance problem in this implementation of Datalog. By not having to spend time thinking of the allocations I felt that I could focus on the functionality instead. Making it work. Dlang have all the tools I need to optimize the memory allocations in the future if I do find out that it is a problem.

Instead of only relying on my word I present the GC statistics when running graspan1 on the Apache dataset (~170mb).

```sh
dub build -b profile-gc
./build/graspan1 http_df
```

```diff
        Number of collections:  55
        Total GC prep time:  2 milliseconds
        Total mark time:  3 milliseconds
        Total sweep time:  17 milliseconds
        Total page recovery time:  1 milliseconds
        Max Pause Time:  0 milliseconds
        Grand total GC time:  25 milliseconds
GC summary: 1215 MB,   55 GC   25 ms, Pauses    6 ms <    0 ms
```

# Addendum 2018-07-26

Post on the [D forum](https://forum.dlang.org/post/irxzxkkxbdunqmtzxmlg@forum.dlang.org).

> Hello,
>
> I've written up a blog post[0] of my explorations when parallelizing Datacat[1].
> It is my thoughts, failures and successes when I wanted to improve the performance by leveraging std.parallelism.
>
> The implementation[2] where "easy" but how to get there wasn't. At least for me. Now in hindsight I know what I should have done but that is the wisdom of looking back.
>
> [0] https://github.com/joakim-brannstrom/blog/blob/master/posts/2018-07-24.md
> [1] https://github.com/joakim-brannstrom/datacat
> [2] https://github.com/joakim-brannstrom/datacat/pull/6

# Addendum 2018-07-26

Something went wrong when I collected the performance metrics for graspan1. The table is updated to reflect the correct values.

The good thing though is that it didn't change the characteristics.

# Addendum 2018-07-26

After studying the implementation and thinking of my original intention of *minimizing* the affected sections I realized that I had failed in one aspect.
I did end up changing `map`, `join` and `antiJoin`. They became aware of the *threading* which I wanted to avoid.

The common aspect that they all end up doing is *inserting* the result into the output. Wouldn't that be the perfect place to put the parallel sort? In the insert? As an additional bonus it would mean that any new functions woudl benefit from the improved sort.

```d
Relation!TupleT rel;
static if (TS == ThreadStrategy.parallel)
    rel.__ctor!(TS)(relation, taskPool);
else
    rel.__ctor!(TS)(relation);
```

Yepp, that is how simple it was.

Lets rerun the benchmarks.

Course grained:
```sh
single   (431 ms, 435 μs, and 9 hnsecs)
parallel (377 ms, 602 μs, and 7 hnsecs)
```

No noticable change. The difference is within the margin of error.

Graspan1 (time in seconds)

| Dataset            | Single | Multi | DataFrog | S vs M | M vs Datafrog |
|--------------------|--------|-------|----------|--------|---------------|
| http_def 169M      | 3.38   | 2.30  | 4.1      | 32%    | 44%           |
| lnx_kernel_df 818M | 20.2   | 14.8  | 21.2     | 27%    | 30%           |
| pgs_df 639M        | 10.1   | 7.4   | 13.5     | 27%    | 45%           |

Now **this** is surprising. Simplifying the code and it doubled the performance. I do not yet know why this happend.

I am a bit sceptical of these numbers so to be sure I have verified the number of computed nodes with DataFrog. They are the same.

I am happy :-)

Simple code is good code.
